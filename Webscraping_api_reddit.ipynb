{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb5ba38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74de2a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Balong\\Desktop\\redditwebscraping\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Balong\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-sentiment. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cuda:0\n",
      "c:\\Users\\Balong\\Desktop\\redditwebscraping\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Balong\\.cache\\huggingface\\hub\\models--j-hartmann--emotion-english-distilroberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'client_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     28\u001b[39m emotion_pipeline = pipeline(\u001b[33m\"\u001b[39m\u001b[33mtext-classification\u001b[39m\u001b[33m\"\u001b[39m, model=emotion_model_name, tokenizer=emotion_model_name, top_k=\u001b[32m1\u001b[39m, device=device)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# --- Reddit Authentication ---\u001b[39;00m\n\u001b[32m     31\u001b[39m reddit = praw.Reddit(\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     client_id=(\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclient_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m),\n\u001b[32m     33\u001b[39m     client_secret=(os.environ[\u001b[33m'\u001b[39m\u001b[33mclient_secret\u001b[39m\u001b[33m'\u001b[39m]),\n\u001b[32m     34\u001b[39m     user_agent=\u001b[33m'\u001b[39m\u001b[33mscript:gaming_trend (by /u/HiGhastlyy)\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     35\u001b[39m     username=(os.environ[\u001b[33m'\u001b[39m\u001b[33musername\u001b[39m\u001b[33m'\u001b[39m]),\n\u001b[32m     36\u001b[39m     password=(os.environ[\u001b[33m'\u001b[39m\u001b[33mpassword\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     37\u001b[39m )\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# --- Subreddits and Data Collection ---\u001b[39;00m\n\u001b[32m     40\u001b[39m subreddits = [\u001b[33m'\u001b[39m\u001b[33mgaming\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpcgaming\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mleagueoflegends\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcs2\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdota2\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33moverwatch\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfortnite\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mapexlegends\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mvalorant\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mminecraft\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:714\u001b[39m, in \u001b[36m__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'client_id'"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- Check for GPU ---\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# --- Sentiment Analysis Setup ---\n",
    "sentiment_model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "sentiment_tokenizer = AutoTokenizer.from_pretrained(sentiment_model_name)\n",
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(sentiment_model_name)\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=sentiment_model, tokenizer=sentiment_tokenizer, device=device)\n",
    "\n",
    "# Sentiment label mapping\n",
    "sentiment_label_map = {\n",
    "    \"LABEL_0\": \"Negative\",\n",
    "    \"LABEL_1\": \"Neutral\",\n",
    "    \"LABEL_2\": \"Positive\"\n",
    "}\n",
    "\n",
    "# --- Emotion Detection Setup ---\n",
    "emotion_model_name = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "emotion_pipeline = pipeline(\"text-classification\", model=emotion_model_name, tokenizer=emotion_model_name, top_k=1, device=device)\n",
    "\n",
    "# --- Reddit Authentication ---\n",
    "reddit = praw.Reddit(\n",
    "    client_id=(os.environ['client_id']),\n",
    "    client_secret=(os.environ['client_secret']),\n",
    "    user_agent='script:gaming_trend (by /u/HiGhastlyy)',\n",
    "    username=(os.environ['username']),\n",
    "    password=(os.environ['password'])\n",
    ")\n",
    "\n",
    "# --- Subreddits and Data Collection ---\n",
    "subreddits = ['gaming', 'pcgaming', 'leagueoflegends', 'cs2', 'dota2', 'overwatch', 'fortnite', 'apexlegends', 'valorant', 'minecraft']\n",
    "posts = []\n",
    "\n",
    "for sub in subreddits:\n",
    "    for post in reddit.subreddit(sub).top(time_filter='year', limit=500):\n",
    "        full_text = f\"{post.title} {post.selftext}\".strip()\n",
    "\n",
    "        if full_text:\n",
    "            # Sentiment\n",
    "            sentiment_result = sentiment_pipeline(full_text[:512])[0]\n",
    "            sentiment = sentiment_label_map[sentiment_result['label']]\n",
    "            sentiment_score = sentiment_result['score']\n",
    "\n",
    "            # Emotion\n",
    "            emotion_result = emotion_pipeline(full_text[:512])[0][0]\n",
    "            emotion = emotion_result['label']\n",
    "            emotion_score = emotion_result['score']\n",
    "        else:\n",
    "            sentiment = \"N/A\"\n",
    "            sentiment_score = 0.0\n",
    "            emotion = \"N/A\"\n",
    "            emotion_score = 0.0\n",
    "\n",
    "        posts.append({\n",
    "            'id': post.id,\n",
    "            'subreddit': sub,\n",
    "            'title': post.title,\n",
    "            'body': post.selftext,\n",
    "            'score': post.score,\n",
    "            'num_comments': post.num_comments,\n",
    "            'created_utc': post.created_utc,\n",
    "            'sentiment': sentiment,\n",
    "            'sentiment_confidence': round(sentiment_score, 3),\n",
    "            'emotion': emotion,\n",
    "            'emotion_confidence': round(emotion_score, 3)\n",
    "        })\n",
    "\n",
    "# --- Save to CSV ---\n",
    "df = pd.DataFrame(posts)\n",
    "df.to_csv(\"reddit_gaming_trends.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Done! Data saved to reddit_gaming_trends.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
