{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cd167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import os\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d0c3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping up to 200 posts from 2023 for query: 'Genshin_Impact'\n",
      "\n",
      "Page 1 — Collected: 0 posts\n",
      "Skipped non-2023 post: 2025 - Teyvat Chapter Interlude Teaser: The Gods' Limits \n",
      "Skipped non-2023 post: 2025 - Behind the Scenes of Genshin Impact \"Let's Start W\n",
      "Skipped non-2023 post: 2025 - Another \"Genshin Impact players can't read\" moment\n",
      "Skipped non-2023 post: 2025 - Youtuber who used genshin impact music has apologi\n",
      "Skipped non-2023 post: 2025 - Chinese players meme about what Genshin Impact wou\n",
      "Skipped non-2023 post: 2025 - Nod-Krai Preview Teaser - \"Prelude to Moonlight\" |\n",
      "Skipped non-2023 post: 2025 - Genshin Impact with more QOL Ideas!!!\n",
      "Skipped non-2023 post: 2024 - Genshin Impact Loses Players' Voice Award from TGA\n",
      "Skipped non-2023 post: 2024 - Genshin Impact Reddit Survey Results!\n",
      "Skipped non-2023 post: 2024 - Ignition Teaser: A Name Forged in Flames | Genshin\n",
      "Skipped non-2023 post: 2025 - Character Trailer - \"Skirk: Lament of a Ruined Wor\n",
      "Skipped non-2023 post: 2024 - Character Trailer - \"Mavuika: Blazing Heart\" | Gen\n",
      "Skipped non-2023 post: 2024 - Natlan Preview Teaser - Need a Hand? | Genshin Imp\n",
      "Skipped non-2023 post: 2025 - Genshin Impact (Hoyoverse) Updates Item Pricing as\n",
      "Skipped non-2023 post: 2025 - Oh nice. Genshin Impact in Germany is no longer F2\n",
      "Skipped non-2023 post: 2025 - Jacob Takanashi (Kinich's new EN VA from Genshin I\n",
      "Skipped non-2023 post: 2024 - Genshin Impact x McDonalds coming soon - 9/17\n",
      "Skipped non-2023 post: 2024 - Congratulations, you just died & got Isekai'd to G\n",
      "Skipped non-2023 post: 2024 - Genshin Impact won ‘Best Mobile Game’ at Gamescom\n",
      "Skipped non-2023 post: 2025 - \"Memories of This Life\" Animated Short | Genshin I\n",
      "Skipped non-2023 post: 2024 - \"The Song Burning in the Embers\" Full Animated Sho\n",
      "Skipped non-2023 post: 2024 - Natlan Preview Teaser - Saurian Wanderings | Gensh\n",
      "No post ID found. Ending early.\n",
      "\n",
      "Scraped 0 posts from 2023. Saved to genshin_impact_2023_posts.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "service = Service(executable_path=\"C:/Windows/chromedriver.exe\")\n",
    "options = Options()\n",
    "options.add_argument('--window-size=1920,1080')\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "options.add_argument(\"user-agent=Mozilla/5.0\")\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "query = \"Genshin_Impact\"\n",
    "target_year = 2023\n",
    "max_results = 200\n",
    "max_pages = 50\n",
    "base_url = f\"https://old.reddit.com/search/?q={query}&sort=relevance&t=all\"\n",
    "\n",
    "all_posts = []\n",
    "seen_urls = set()\n",
    "count = 0\n",
    "after = None\n",
    "page = 0\n",
    "\n",
    "print(f\"\\nScraping up to {max_results} posts from {target_year} for query: '{query}'\")\n",
    "driver.get(base_url)\n",
    "time.sleep(5)\n",
    "\n",
    "def is_target_year(dt_text):\n",
    "    try:\n",
    "        dt = datetime.strptime(dt_text, \"%Y-%m-%dT%H:%M:%S+00:00\")\n",
    "        return dt.year == target_year, dt\n",
    "    except:\n",
    "        return False, None\n",
    "\n",
    "while len(all_posts) < max_results and page < max_pages:\n",
    "    print(f\"\\nPage {page + 1} — Collected: {len(all_posts)} posts\")\n",
    "\n",
    "    posts = driver.find_elements(By.CSS_SELECTOR, \"div.search-result\")\n",
    "    last_post_id = None\n",
    "\n",
    "    for post in posts:\n",
    "        try:\n",
    "            title_elem = post.find_element(By.CSS_SELECTOR, \"a.search-title\")\n",
    "            time_elem = post.find_element(By.CSS_SELECTOR, \"span.search-time > time\")\n",
    "            url = title_elem.get_attribute(\"href\")\n",
    "            title = title_elem.text.strip()\n",
    "            time_iso = time_elem.get_attribute(\"datetime\")\n",
    "\n",
    "            subreddit_elem = post.find_element(By.CSS_SELECTOR, \"a.search-subreddit-link\")\n",
    "            subreddit = subreddit_elem.text.strip().replace(\"r/\", \"\")\n",
    "\n",
    "            full_id = post.get_attribute(\"data-fullname\")\n",
    "\n",
    "            if not url or url in seen_urls:\n",
    "                continue\n",
    "            seen_urls.add(url)\n",
    "\n",
    "            valid, dt = is_target_year(time_iso)\n",
    "            if not valid:\n",
    "                try:\n",
    "                    other_dt = datetime.strptime(time_iso, \"%Y-%m-%dT%H:%M:%S+00:00\")\n",
    "                    print(f\"Skipped non-{target_year} post: {other_dt.year} - {title[:50]}\")\n",
    "                except:\n",
    "                    pass\n",
    "                continue\n",
    "\n",
    "            all_posts.append({\n",
    "                \"Subreddit\": subreddit,\n",
    "                \"Year\": dt.year,\n",
    "                \"Month\": dt.month,\n",
    "                \"Text\": title,\n",
    "                \"Created_utc\": dt.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            })\n",
    "            print(f\"[{dt.date()}] r/{subreddit} - {title[:60]}\")\n",
    "\n",
    "            if full_id:\n",
    "                last_post_id = full_id\n",
    "\n",
    "            if len(all_posts) >= max_results:\n",
    "                break\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if not last_post_id:\n",
    "        print(\"No post ID found. Ending early.\")\n",
    "        break\n",
    "\n",
    "    page += 1\n",
    "    count += len(posts)\n",
    "    after = last_post_id\n",
    "    next_url = f\"https://old.reddit.com/search/?q={query}&sort=relevance&t=all&count={count}&after={after}\"\n",
    "\n",
    "    print(f\"Next: {next_url}\")\n",
    "    driver.get(next_url)\n",
    "    time.sleep(4)\n",
    "\n",
    "# --- Save results ---\n",
    "driver.quit()\n",
    "df = pd.DataFrame(all_posts)\n",
    "output_file = f\"{query.lower()}_{target_year}_posts.csv\"\n",
    "df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "print(f\"\\nScraped {len(df)} posts from {target_year}. Saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ada61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{query}_{target_year}_posts.csv\")\n",
    "df = df[df['Subreddit'].str.contains(query, case=False, na=False)]\n",
    "df['Year'] = pd.to_datetime(df['Created_utc']).dt.year\n",
    "df['Month'] = pd.to_datetime(df['Created_utc']).dt.month\n",
    "df = df[[\"Subreddit\", \"Year\", \"Month\", \"Text\", \"Created_utc\"]]\n",
    "df.to_csv(f\"{query}-{target_year}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d046e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged 9 files into 'merged_2024data.csv' with 428 total rows (max 200 from each).\n"
     ]
    }
   ],
   "source": [
    "folder_path = f\"{target_year} data\"\n",
    "output_file = f\"merged_{target_year}data.csv\"\n",
    "\n",
    "csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "\n",
    "    if 'year' in df.columns:\n",
    "        df = df[df['year'] == 2024]\n",
    "    df = df.head(200)\n",
    "    if not df.empty:\n",
    "        dfs.append(df)\n",
    "\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "merged_df.to_csv(output_file, index=False, encoding='utf-8')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
